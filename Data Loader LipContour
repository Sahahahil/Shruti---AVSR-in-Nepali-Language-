import cv2
import mediapipe as mp
import numpy as np
import os

# ------------------------
# SETTINGS
# ------------------------
NUM_CLASSES = 10
FRAMES_PER_SAMPLE = 50  # 50 frames per sample nai chaiiyo /OR do you want it to be 60??
SAMPLES_PER_CLASS = 5   # number of independent samples per class/ kati ota sample per class load garne ta
DATA_DIR = "data"

# Create class folders if they don't exist
for c in range(NUM_CLASSES):
    class_path = os.path.join(DATA_DIR, f"class_{c}")
    os.makedirs(class_path, exist_ok=True)

# MediaPipe Face Mesh
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# Lip landmarks
OUTER_LIPS = [
    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,
    291, 375, 321, 405, 314, 17, 84, 181, 91, 146
]
INNER_LIPS = [
    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,
    308, 324, 318, 402, 317, 14, 87, 178, 88, 95
]

# Padding & aspect ratio
PAD_X, PAD_Y = 30, 15
ASPECT_RATIO = 2.0  # width / height

# Camera
cap = cv2.VideoCapture(0)

# ------------------------
# MAIN LOOP
# ------------------------
for class_idx in range(NUM_CLASSES):
    print(f"\n--- CLASS {class_idx} ---")

    samples_collected = 0

    while samples_collected < SAMPLES_PER_CLASS:
        print(f"\nPress 's' to start sample {samples_collected + 1} for class {class_idx}")
        # Wait for user to press 's'
        while True:
            ret, frame = cap.read()
            if not ret:
                continue
            cv2.putText(frame, f"Class {class_idx}, Sample {samples_collected+1}: Press 's' to start",
                        (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
            cv2.imshow("Camera", frame)
            if cv2.waitKey(1) & 0xFF == ord('s'):
                break

        frame_count = 0
        sample_folder = os.path.join(DATA_DIR, f"class_{class_idx}", f"sample_{samples_collected}")
        os.makedirs(sample_folder, exist_ok=True)

        print(f"Recording {FRAMES_PER_SAMPLE} frames for sample {samples_collected+1}...")
        while frame_count < FRAMES_PER_SAMPLE:
            ret, frame = cap.read()
            if not ret:
                continue

            h, w, _ = frame.shape
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(rgb)

            if results.multi_face_landmarks:
                face_landmarks = results.multi_face_landmarks[0]

                # Lip ROI
                outer_pts = np.array([[int(face_landmarks.landmark[i].x * w),
                                       int(face_landmarks.landmark[i].y * h)] for i in OUTER_LIPS], np.int32)
                inner_pts = np.array([[int(face_landmarks.landmark[i].x * w),
                                       int(face_landmarks.landmark[i].y * h)] for i in INNER_LIPS], np.int32)

                x, y, bw, bh = cv2.boundingRect(outer_pts)
                x = max(0, x - PAD_X)
                y = max(0, y - PAD_Y)
                bw = min(w - x, bw + 2 * PAD_X)
                bh = min(h - y, bh + 2 * PAD_Y)

                desired_bw = int(ASPECT_RATIO * bh)
                dw = desired_bw - bw
                x = max(0, x - dw // 2)
                bw = min(w - x, desired_bw)

                lip_roi = np.ones((bh, bw, 3), dtype=np.uint8) * 255
                outer_shifted = outer_pts - [x, y]
                inner_shifted = inner_pts - [x, y]
                cv2.fillPoly(lip_roi, [outer_shifted], (180, 180, 180))
                cv2.fillPoly(lip_roi, [inner_shifted], (0, 0, 0))

                # Normalize & resize
                lip_norm = cv2.resize(lip_roi, (128, 64))
                lip_norm = lip_norm.astype(np.float32) / 255.0

                # Save frame
                save_path = os.path.join(sample_folder, f"{frame_count}.png")
                cv2.imwrite(save_path, (lip_norm * 255).astype(np.uint8))

                frame_count += 1
                cv2.imshow("Lip ROI", lip_norm)

            cv2.imshow("Camera", frame)
            if cv2.waitKey(1) & 0xFF == 27:
                break

        samples_collected += 1
        print(f"Sample {samples_collected} for class {class_idx} collected.")

    print(f"Total samples collected for class {class_idx}: {samples_collected}")

cap.release()
cv2.destroyAllWindows()
print("Data collection completed for all classes.")
