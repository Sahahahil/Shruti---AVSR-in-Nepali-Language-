{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4582558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fde790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_face(detections, w, h, px=0.5, py=0.65):\n",
    "    \"\"\"\n",
    "    To Select da face closest to da fokin priority point (px, py) in normalized coords.\n",
    "    \"\"\"\n",
    "    best_det = None\n",
    "    best_dist = float(\"inf\")\n",
    "\n",
    "    for det in detections:\n",
    "        bbox = det.location_data.relative_bounding_box\n",
    "\n",
    "        cx = (bbox.xmin + bbox.width / 2) * w\n",
    "        cy = (bbox.ymin + bbox.height / 2) * h\n",
    "\n",
    "        dx = cx - (px * w)\n",
    "        dy = cy - (py * h)\n",
    "        dist = dx * dx + dy * dy  \n",
    "\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_det = det\n",
    "\n",
    "    return best_det\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lip_frames(\n",
    "    video_path,\n",
    "    out_dir,\n",
    "    start_time=0,\n",
    "    end_time=None,\n",
    "    priority_x=0.5,\n",
    "    priority_y=0.65,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract Bhigi hoth frames using MP(CPU),\n",
    "    prioritizing the face nearest to the specified region px,py.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸŽ¥ Video: {fps:.2f} fps | {total_frames} frames | {duration:.2f}s\")\n",
    "\n",
    "    if end_time is None or end_time > duration:\n",
    "        end_time = duration\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "    frame_idx = 0\n",
    "    detected = 0\n",
    "\n",
    "    face_det = None\n",
    "\n",
    "    try:\n",
    "        face_det = mp.solutions.face_detection.FaceDetection(\n",
    "            model_selection=1,\n",
    "            min_detection_confidence=0.3\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "            if current_time > end_time:\n",
    "                break\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize large frames for speed\n",
    "            h, w = frame.shape[:2]\n",
    "            if w > 960:\n",
    "                scale = 960 / w\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "                h, w = frame.shape[:2]\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_det.process(rgb)\n",
    "\n",
    "            if results.detections:\n",
    "                det = choose_best_face(\n",
    "                    results.detections,\n",
    "                    w, h,\n",
    "                    px=priority_x,\n",
    "                    py=priority_y\n",
    "                )\n",
    "\n",
    "                if det is not None:\n",
    "                    bbox = det.location_data.relative_bounding_box\n",
    "\n",
    "                    x1 = int(bbox.xmin * w)\n",
    "                    y1 = int(bbox.ymin * h)\n",
    "                    bw = int(bbox.width * w)\n",
    "                    bh = int(bbox.height * h)\n",
    "\n",
    "                    # Focus on lower face (mouth region)\n",
    "                    y1 = y1 + int(bh * 0.4)\n",
    "                    bh = int(bh * 0.6)\n",
    "\n",
    "                    # Padding + clipping\n",
    "                    pad = 10\n",
    "                    x1 = max(x1 - pad, 0)\n",
    "                    y1 = max(y1 - pad, 0)\n",
    "                    x2 = min(x1 + bw + 2 * pad, w)\n",
    "                    y2 = min(y1 + bh + 2 * pad, h)\n",
    "\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    if crop.size > 0:\n",
    "                        cv2.imwrite(\n",
    "                            os.path.join(out_dir, f\"{frame_idx:06d}.jpg\"),\n",
    "                            crop\n",
    "                        )\n",
    "                        detected += 1\n",
    "\n",
    "            frame_idx += 1\n",
    "\n",
    "            # garbage collection happening\n",
    "            if frame_idx % 200 == 0:\n",
    "                gc.collect()\n",
    "\n",
    "    finally:\n",
    "        if face_det is not None:\n",
    "            face_det.close()\n",
    "        cap.release()\n",
    "        gc.collect()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸŽ¬ Extracted {detected}/{frame_idx} frames\")\n",
    "        if detected == 0:\n",
    "            print(\"âš ï¸ WARNING: No face detected in any frame\")\n",
    "\n",
    "    return detected > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f0660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¥ Video: 29.97 fps | 2485 frames | 82.92s\n",
      "ðŸŽ¬ Extracted 301/301 frames\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_lip_frames(\n",
    "    video_path=\"C:/MajorProject/cropped_videos/Sample1.mp4\",\n",
    "    out_dir=\"lip_frames\",\n",
    "    start_time=0,\n",
    "    end_time=10,\n",
    "    priority_x=0.7,   # x cord from top left\n",
    "    priority_y=0.3,  # y cord from top left\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee250b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "majorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
