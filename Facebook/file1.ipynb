{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324c7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, subprocess, cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import yt_dlp, mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "from aeneas.executetask import ExecuteTask\n",
    "from aeneas.task import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde52525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760431104.598061   96470 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1760431104.601003   97139 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.2.4-arch1.2), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1760431104.603288   97133 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# ---------- CONFIG ----------\n",
    "DATA_ROOT = \"dataset\"\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "# NOTE: Do NOT create a global FaceMesh instance. Creating and reusing a single\n",
    "# FaceMesh object across threads or across different video captures can cause\n",
    "# crashes (segfaults) in some environments. Instead create a FaceMesh instance\n",
    "# locally inside the processing function (see `extract_lip_frames`).\n",
    "# mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5423af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1760431104.612307   97134 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# ---------- DOWNLOAD ----------\n",
    "def download_fb_video(url, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    ydl_opts = {\n",
    "        \"outtmpl\": os.path.join(out_dir, \"%(id)s.%(ext)s\"),\n",
    "        \"format\": \"best[ext=mp4]\",\n",
    "        \"quiet\": True,\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "    return os.path.join(out_dir, f\"{info['id']}.mp4\"), info[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2ed479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- AUDIO ----------\n",
    "def extract_audio(video_path, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, os.path.basename(video_path).replace(\".mp4\", \".wav\"))\n",
    "    cmd = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-ac\", \"1\", \"-ar\", \"16000\", out_path]\n",
    "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7953fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LIP FRAMES ----------\n",
    "def extract_lip_frames(video_path, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_idx = 0\n",
    "    # Create FaceMesh locally per invocation to avoid sharing across threads.\n",
    "    with mp.solutions.face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb)\n",
    "            if results and getattr(results, 'multi_face_landmarks', None):\n",
    "                landmarks = results.multi_face_landmarks[0].landmark\n",
    "                # Some videos may have fewer landmark points; guard against that.\n",
    "                if len(landmarks) >= 88:\n",
    "                    lip_points = [(int(l.x * frame.shape[1]), int(l.y * frame.shape[0])) for l in landmarks[61:88]]\n",
    "                    xs, ys = zip(*lip_points)\n",
    "                    x1, x2 = max(min(xs)-10,0), min(max(xs)+10, frame.shape[1])\n",
    "                    y1, y2 = max(min(ys)-10,0), min(max(ys)+10, frame.shape[0])\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "                    cv2.imwrite(os.path.join(out_dir, f\"{frame_idx:06d}.jpg\"), crop)\n",
    "            frame_idx += 1\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee63e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- ALIGNMENT ----------\n",
    "def align_audio_text(audio_path, text, out_path):\n",
    "    tmp_text = os.path.join(os.path.dirname(out_path), \"temp.txt\")\n",
    "    with open(tmp_text, \"w\", encoding=\"utf-8\") as f: f.write(text)\n",
    "    task = Task(config_string=\"task_language=eng|is_text_type=plain|os_task_file_format=tsv\")\n",
    "    task.audio_file_path_absolute = audio_path\n",
    "    task.text_file_path_absolute = tmp_text\n",
    "    task.output_file_path_absolute = out_path\n",
    "    ExecuteTask(task).execute()\n",
    "    task.output_sync_map_file(out_path)\n",
    "    os.remove(tmp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8917e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------- PROCESS ONE SAMPLE ----------\n",
    "def process_sample(url, title):\n",
    "    try:\n",
    "        video_path, vid_id = download_fb_video(url, os.path.join(DATA_ROOT, \"videos\"))\n",
    "        audio_path = extract_audio(video_path, os.path.join(DATA_ROOT, \"audio\"))\n",
    "        frame_dir = os.path.join(DATA_ROOT, \"frames\", vid_id)\n",
    "        extract_lip_frames(video_path, frame_dir)\n",
    "        align_path = os.path.join(DATA_ROOT, \"alignments\", f\"{vid_id}.tsv\")\n",
    "        os.makedirs(os.path.dirname(align_path), exist_ok=True)\n",
    "        align_audio_text(audio_path, title, align_path)\n",
    "        meta = {\n",
    "            \"id\": vid_id,\n",
    "            \"url\": url,\n",
    "            \"text\": title,\n",
    "            \"video\": video_path,\n",
    "            \"audio\": audio_path,\n",
    "            \"frames_dir\": frame_dir,\n",
    "            \"alignment\": align_path,\n",
    "        }\n",
    "        json.dump(meta, open(os.path.join(DATA_ROOT, f\"{vid_id}.json\"), \"w\", encoding=\"utf-8\"), indent=2)\n",
    "        return vid_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             \r"
     ]
    }
   ],
   "source": [
    "# ---------- MAIN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # List of (URL, title) pairs\n",
    "    videos = [\n",
    "        (\"https://www.facebook.com/share/v/1CdiEnT1xw/\", \"विराटनगरको जिल्ला कारागार मोरङमा कैदीबन्दी जीवन बिताइरहेका एकजनाको आज दिउँसो मृत्यु भएको छ ।\"),\n",
    "        (\"https://www.facebook.com/share/v/17YKEbmgt8/\", \"विराटनगरको वडानम्बर १६ बर्माटोलका बासिन्दा सिनो तथा फोहोरको दुर्गन्धका कारण पीडित भएका छन । फोहोरका कारण उत्सर्जन हुने हानिकारण ग्याँस र दुर्गन्धका कारण सो क्षेत्रका बासिन्दा घरकोठामैं मास्क लगाएर बस्नुपर्ने अवस्था सृजना भएको छ ।\"),\n",
    "    ]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as ex:\n",
    "        for _ in tqdm(ex.map(lambda v: process_sample(*v), videos), total=len(videos)):\n",
    "            pass\n",
    "    print(\"✅ Dataset build complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
