{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fde790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_face(detections, w, h, px=0.5, py=0.65):\n",
    "    \"\"\"\n",
    "    To Select da face closest to da fokin priority point (px, py) in normalized coords.\n",
    "    \"\"\"\n",
    "    best_det = None\n",
    "    best_dist = float(\"inf\")\n",
    "\n",
    "    for det in detections:\n",
    "        bbox = det.location_data.relative_bounding_box\n",
    "\n",
    "        cx = (bbox.xmin + bbox.width / 2) * w\n",
    "        cy = (bbox.ymin + bbox.height / 2) * h\n",
    "\n",
    "        dx = cx - (px * w)\n",
    "        dy = cy - (py * h)\n",
    "        dist = dx * dx + dy * dy  \n",
    "\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_det = det\n",
    "\n",
    "    return best_det\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1677899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lip_frames(\n",
    "    video_path,\n",
    "    out_dir,\n",
    "    start_time=0,\n",
    "    end_time=None,\n",
    "    priority_x=0.5,\n",
    "    priority_y=0.65,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract Bhigi hoth frames using MP(CPU),\n",
    "    prioritizing the face nearest to the specified region px,py.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸŽ¥ Video: {fps:.2f} fps | {total_frames} frames | {duration:.2f}s\")\n",
    "\n",
    "    if end_time is None or end_time > duration:\n",
    "        end_time = duration\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "    frame_idx = 0\n",
    "    detected = 0\n",
    "\n",
    "    face_det = None\n",
    "\n",
    "    try:\n",
    "        face_det = mp.solutions.face_detection.FaceDetection(\n",
    "            model_selection=1,\n",
    "            min_detection_confidence=0.3\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "            if current_time > end_time:\n",
    "                break\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize large frames for speed\n",
    "            h, w = frame.shape[:2]\n",
    "            if w > 960:\n",
    "                scale = 960 / w\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "                h, w = frame.shape[:2]\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_det.process(rgb)\n",
    "\n",
    "            if results.detections:\n",
    "                det = choose_best_face(\n",
    "                    results.detections,\n",
    "                    w, h,\n",
    "                    px=priority_x,\n",
    "                    py=priority_y\n",
    "                )\n",
    "\n",
    "                if det is not None:\n",
    "                    bbox = det.location_data.relative_bounding_box\n",
    "\n",
    "                    x1 = int(bbox.xmin * w)\n",
    "                    y1 = int(bbox.ymin * h)\n",
    "                    bw = int(bbox.width * w)\n",
    "                    bh = int(bbox.height * h)\n",
    "\n",
    "                    # Focus on lower face (mouth region)\n",
    "                    y1 = y1 + int(bh * 0.4)\n",
    "                    bh = int(bh * 0.6)\n",
    "\n",
    "                    # Padding + clipping\n",
    "                    pad = 10\n",
    "                    x1 = max(x1 - pad, 0)\n",
    "                    y1 = max(y1 - pad, 0)\n",
    "                    x2 = min(x1 + bw + 2 * pad, w)\n",
    "                    y2 = min(y1 + bh + 2 * pad, h)\n",
    "\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    if crop.size > 0:\n",
    "                        cv2.imwrite(\n",
    "                            os.path.join(out_dir, f\"{frame_idx:06d}.jpg\"),\n",
    "                            crop\n",
    "                        )\n",
    "                        detected += 1\n",
    "\n",
    "            frame_idx += 1\n",
    "\n",
    "            # garbage collection happening\n",
    "            if frame_idx % 200 == 0:\n",
    "                gc.collect()\n",
    "\n",
    "    finally:\n",
    "        if face_det is not None:\n",
    "            face_det.close()\n",
    "        cap.release()\n",
    "        gc.collect()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸŽ¬ Extracted {detected}/{frame_idx} frames\")\n",
    "        if detected == 0:\n",
    "            print(\"âš ï¸ WARNING: No face detected in any frame\")\n",
    "\n",
    "    return detected > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e52b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¥ Video: 29.97 fps | 2485 frames | 82.92s\n",
      "ðŸŽ¬ Extracted 301/301 frames\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "extract_lip_frames(\n",
    "    video_path=\"C:/MajorProject/cropped_videos/Sample1.mp4\",\n",
    "    out_dir=\"lip_frames\",\n",
    "    start_time=0,\n",
    "    end_time=10,\n",
    "    priority_x=0.7,   # x cord from top left\n",
    "    priority_y=0.35,  # y cord from top left\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee250b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- LIP LANDMARK INDICES ----------------\n",
    "LIP_LANDMARKS = [\n",
    "    61, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 95, 88, 178, 87, 14, 317, 402, 318, 324\n",
    "]\n",
    "\n",
    "# ---------------- COMPLETENESS SCORING ----------------\n",
    "def lip_completeness_score(landmarks, w, h):\n",
    "    valid = 0\n",
    "    for idx in LIP_LANDMARKS:\n",
    "        lm = landmarks[idx]\n",
    "        x, y = lm.x * w, lm.y * h\n",
    "        if 0 <= x < w and 0 <= y < h:\n",
    "            valid += 1\n",
    "    return valid / len(LIP_LANDMARKS)\n",
    "\n",
    "\n",
    "def choose_best_face_mesh(multi_face_landmarks, w, h, px=0.5, py=0.65, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Chooses face with maximum visible lip landmarks,\n",
    "    biased toward priority position (px, py).\n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best_face = None\n",
    "\n",
    "    for face in multi_face_landmarks:\n",
    "        completeness = lip_completeness_score(face.landmark, w, h)\n",
    "\n",
    "        xs = [face.landmark[i].x for i in LIP_LANDMARKS]\n",
    "        ys = [face.landmark[i].y for i in LIP_LANDMARKS]\n",
    "        cx, cy = np.mean(xs), np.mean(ys)\n",
    "\n",
    "        dist = np.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n",
    "        spatial_score = 1 / (dist + 1e-6)\n",
    "\n",
    "        score = alpha * completeness + (1 - alpha) * spatial_score\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_face = face\n",
    "\n",
    "    return best_face, best_score\n",
    "\n",
    "\n",
    "# ---------------- MAIN EXTRACTION FUNCTION ----------------\n",
    "def extract_lip_frames(\n",
    "    video_path,\n",
    "    out_dir,\n",
    "    start_time=0,\n",
    "    end_time=None,\n",
    "    priority_x=0.5,\n",
    "    priority_y=0.65,\n",
    "    min_completeness=0.7,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract lip-region frames using MediaPipe FaceMesh.\n",
    "    Selects face with maximum visible lip landmarks.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    if end_time is None or end_time > duration:\n",
    "        end_time = duration\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸŽ¥ {fps:.2f} fps | {total_frames} frames | {duration:.2f}s\")\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "    frame_idx = int(start_time * fps)\n",
    "    detected = 0\n",
    "\n",
    "    face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        max_num_faces=3,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "            if current_time > end_time:\n",
    "                break\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            if w > 960:\n",
    "                scale = 960 / w\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "                h, w = frame.shape[:2]\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                face, score = choose_best_face_mesh(\n",
    "                    results.multi_face_landmarks,\n",
    "                    w, h,\n",
    "                    px=priority_x,\n",
    "                    py=priority_y\n",
    "                )\n",
    "\n",
    "                if face and score >= min_completeness:\n",
    "                    xs, ys = [], []\n",
    "                    for idx in LIP_LANDMARKS:\n",
    "                        lm = face.landmark[idx]\n",
    "                        xs.append(int(lm.x * w))\n",
    "                        ys.append(int(lm.y * h))\n",
    "\n",
    "                    x1, x2 = max(min(xs) - 10, 0), min(max(xs) + 10, w)\n",
    "                    y1, y2 = max(min(ys) - 10, 0), min(max(ys) + 10, h)\n",
    "\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "                    if crop.size > 0:\n",
    "                        cv2.imwrite(\n",
    "                            os.path.join(out_dir, f\"{frame_idx:06d}.jpg\"),\n",
    "                            crop\n",
    "                        )\n",
    "                        detected += 1\n",
    "\n",
    "            frame_idx += 1\n",
    "            if frame_idx % 200 == 0:\n",
    "                gc.collect()\n",
    "\n",
    "    finally:\n",
    "        face_mesh.close()\n",
    "        cap.release()\n",
    "        gc.collect()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸŽ¬ Extracted {detected} lip frames\")\n",
    "        if detected == 0:\n",
    "            print(\"âš ï¸ No valid lip landmarks detected\")\n",
    "\n",
    "    return detected > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a126b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¥ 29.97 fps | 2485 frames | 82.92s\n",
      "ðŸŽ¬ Extracted 138 lip frames\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "extract_lip_frames(\n",
    "    video_path=\"C:/MajorProject/cropped_videos/Sample1.mp4\",\n",
    "    out_dir=\"lip_frames\",\n",
    "    start_time=0,\n",
    "    end_time=10,\n",
    "    priority_x=0.7,   # x cord from top left\n",
    "    priority_y=0.35,  # y cord from top left\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "TSV_PATH = \"C:/MajorProject/19-Dec.tsv\"\n",
    "VIDEO_DIR = \"C:/MajorProject/video_dataset\"\n",
    "OUTPUT_ROOT = \"C:/MajorProject/lip_frames\"\n",
    "\n",
    "VIDEO_EXT = \".mp4\"\n",
    "\n",
    "PRIORITY_X = 0.7\n",
    "PRIORITY_Y = 0.35\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "def extract_end_time_from_text(text):\n",
    "    \"\"\"\n",
    "    Extracts the LAST numeric value from text.\n",
    "    Works for:\n",
    "    '... 0.0 11.0'\n",
    "    '... 0:00 1:05'\n",
    "    \"\"\"\n",
    "    tokens = text.strip().split()\n",
    "\n",
    "    # Try from end backwards\n",
    "    for token in reversed(tokens):\n",
    "        if re.match(r\"^\\d+(\\.\\d+)?$\", token) or \":\" in token:\n",
    "            return parse_time_to_seconds(token)\n",
    "\n",
    "    raise ValueError(f\"No valid time found in: {text}\")\n",
    "\n",
    "\n",
    "def parse_time_to_seconds(t):\n",
    "    t = str(t).strip()\n",
    "\n",
    "    if \":\" in t:\n",
    "        parts = [float(p) for p in t.split(\":\")]\n",
    "        if len(parts) == 2:\n",
    "            return parts[0] * 60 + parts[1]\n",
    "        if len(parts) == 3:\n",
    "            return parts[0] * 3600 + parts[1] * 60 + parts[2]\n",
    "\n",
    "    return float(t)\n",
    "\n",
    "\n",
    "def batch_extract_from_custom_tsv():\n",
    "    os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "    with open(TSV_PATH, encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "\n",
    "        for idx, row in enumerate(reader, start=1):\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "\n",
    "            base_name = row[0].strip()\n",
    "            text_block = row[1]\n",
    "\n",
    "            try:\n",
    "                end_time = extract_end_time_from_text(text_block)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ [{idx}] Time parse failed: {e}\")\n",
    "                continue\n",
    "\n",
    "            video_file = base_name + VIDEO_EXT\n",
    "            video_path = os.path.join(VIDEO_DIR, video_file)\n",
    "\n",
    "            if not os.path.exists(video_path):\n",
    "                print(f\"âŒ [{idx}] Video not found: {video_file}\")\n",
    "                continue\n",
    "\n",
    "            out_dir = os.path.join(OUTPUT_ROOT, base_name)\n",
    "\n",
    "            print(f\"\\nâ–¶ [{idx}] Processing: {video_file}\")\n",
    "            print(f\"â± End time: {end_time}s\")\n",
    "\n",
    "            extract_lip_frames(\n",
    "                video_path=video_path,\n",
    "                out_dir=out_dir,\n",
    "                start_time=0,\n",
    "                end_time=end_time,\n",
    "                priority_x=PRIORITY_X,\n",
    "                priority_y=PRIORITY_Y,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_extract_from_custom_tsv()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "majorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
